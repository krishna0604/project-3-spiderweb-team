# -*- coding: utf-8 -*-
"""Postgre_to_Bigquery_Project_3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1K8Q18VRg1_gSyD26vZ_WMkLLIAg1ZHLj

Menginstal Library yang Diperlukan

Kamu perlu menginstal library psycopg2 untuk menghubungkan PostgreSQL dan pandas-gbq untuk mengunggah ke BigQuery. Jalankan kode berikut di sel Colab:
"""

!pip install psycopg2-binary pandas-gbq google-cloud-bigquery

"""/spiderweb3-7a16d1d8cbf2.json"""

!pip install google-cloud-bigquery pandas-gbq

"""Gunakan kode berikut untuk mengunggah DataFrame ke BigQuery"""

from google.cloud import bigquery
from google.oauth2 import service_account

# Ganti dengan path ke file JSON kredensial yang diunggah
key_path = '/spiderweb3-7a16d1d8cbf2.json'

# Membuat client BigQuery
credentials = service_account.Credentials.from_service_account_file(key_path)
client = bigquery.Client(credentials=credentials, project=credentials.project_id)

"""Mengunggah DataFrame ke BigQuery dengan pandas-gbq:"""

!pip install psycopg2-binary google-cloud-bigquery

"""Ketahui informasi koneksi ke PostgreSQL kamu (host, database, user, password). Ganti placeholder dengan informasi tersebut."""

import psycopg2
import pandas as pd

# Informasi koneksi
conn = psycopg2.connect(
    host="47.237.106.32",
    database="spiderweb_db",
    user="spiderweb_p3",
    password="spiderweb_p3"
)

# Membuat cursor
cursor = conn.cursor()

# Mendapatkan nama-nama tabel
cursor.execute("""SELECT table_name FROM information_schema.tables
   WHERE table_schema = 'public'""")
tables = cursor.fetchall()

# Tampilkan daftar tabel
for table in tables:
    print(table[0])

def read_table_to_df(table_name):
    query = f"SELECT * FROM {table_name}"
    df = pd.read_sql_query(query, conn)
    return df

# Contoh membaca tabel pertama
table_name = tables[0][0]  # nama tabel pertama
df = read_table_to_df(table_name)
print(df.head())

from google.cloud import bigquery

def upload_to_bigquery(df, table_id):
    job_config = bigquery.LoadJobConfig(
        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,
    )
    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)
    job.result()  # Tunggu hingga pekerjaan selesai
    print(f"Data berhasil diunggah ke {table_id}!")

# Nama project dan dataset di BigQuery
project_id = 'spiderweb3'
dataset_id = 'spiderweb_p3'

# Loop untuk mengunggah setiap tabel ke BigQuery
for table in tables:
    table_name = table[0]
    print(f"Mengunggah tabel {table_name}...")
    df = read_table_to_df(table_name)
    table_id = f"{project_id}.{dataset_id}.{table_name}"
    upload_to_bigquery(df, table_id)